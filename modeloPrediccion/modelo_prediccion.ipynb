{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "1oPnVfHEoCkw",
        "outputId": "05359624-3852-488a-d242-5d741e81f167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cargado exitosamente.\n",
            "Filas originales: 9236\n",
            "Filas después de eliminar nulos/vacíos en 'Ciudad' o 'Comentario': 9236\n",
            "Columna 'Comentario' eliminada.\n",
            "\n",
            "Dataset después de la limpieza:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ciudad</th>\n",
              "      <th>Categoría del problema</th>\n",
              "      <th>Categoria numerica</th>\n",
              "      <th>Nivel de urgencia</th>\n",
              "      <th>Fecha del reporte</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Manizales</td>\n",
              "      <td>Seguridad</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-08-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Santa Marta</td>\n",
              "      <td>Educación</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-04-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medellín</td>\n",
              "      <td>Medio Ambiente</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-06-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bogotá</td>\n",
              "      <td>Medio Ambiente</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-06-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manizales</td>\n",
              "      <td>Educación</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2024-07-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Ciudad Categoría del problema  Categoria numerica  Nivel de urgencia  \\\n",
              "0    Manizales              Seguridad                   3                  3   \n",
              "1  Santa Marta              Educación                   2                  1   \n",
              "2     Medellín         Medio Ambiente                   4                  1   \n",
              "3       Bogotá         Medio Ambiente                   4                  1   \n",
              "4    Manizales              Educación                   2                  4   \n",
              "\n",
              "  Fecha del reporte  \n",
              "0        2023-08-11  \n",
              "1        2023-04-12  \n",
              "2        2023-06-09  \n",
              "3        2023-06-04  \n",
              "4        2024-07-10  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Filas finales: 9236\n",
            "\n",
            "Dataset procesado guardado como dataset_procesado_para_prediccion.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset que contiene las columnas necesarias\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset_final_preparado.csv\")\n",
        "    print(\"Dataset cargado exitosamente.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: dataset_final_preparado.csv no encontrado. Asegúrate de que el archivo existe.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Filas originales: {len(df)}\")\n",
        "\n",
        "# Eliminar filas con valores nulos o vacíos en 'Ciudad' y 'Comentario'\n",
        "# Keep original df for potential future use before dropping columns\n",
        "df_cleaned = df.dropna(subset=['Ciudad', 'Comentario']).copy()\n",
        "df_cleaned = df_cleaned[df_cleaned['Ciudad'].astype(str).str.strip() != '']\n",
        "df_cleaned = df_cleaned[df_cleaned['Comentario'].astype(str).str.strip() != '']\n",
        "\n",
        "print(f\"Filas después de eliminar nulos/vacíos en 'Ciudad' o 'Comentario': {len(df_cleaned)}\")\n",
        "\n",
        "# Eliminar la columna 'Comentario'\n",
        "if 'Comentario' in df_cleaned.columns:\n",
        "    df_cleaned = df_cleaned.drop(columns=['Comentario']).copy()\n",
        "    print(\"Columna 'Comentario' eliminada.\")\n",
        "\n",
        "# Now, instead of selecting a subset, keep all remaining columns\n",
        "df_procesado = df_cleaned.copy()\n",
        "\n",
        "print(\"\\nDataset después de la limpieza:\")\n",
        "display(df_procesado.head())\n",
        "\n",
        "print(f\"\\nFilas finales: {len(df_procesado)}\")\n",
        "\n",
        "# Puedes guardar este DataFrame procesado si lo necesitas para pasos posteriores\n",
        "df_procesado.to_csv(\"dataset_procesado_para_prediccion.csv\", index=False)\n",
        "print(\"\\nDataset procesado guardado como dataset_procesado_para_prediccion.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co1k94E79GvN",
        "outputId": "535249c4-a5ae-43ac-9114-16bad0520630"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "['Nivel de Urgencia']",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_7376\\67310600.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m df = pd.read_csv(\u001b[33m'dataset_procesado_para_prediccion.csv'\u001b[39m)\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Paso 3: Convertir fecha y crear mes\u001b[39;00m\n\u001b[32m     11\u001b[39m df[\u001b[33m'Fecha'\u001b[39m] = pd.to_datetime(df[\u001b[33m'Fecha del reporte'\u001b[39m], format=\u001b[33m'%Y %m %d'\u001b[39m, errors=\u001b[33m'coerce'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = df.dropna(subset=[\u001b[33m'Fecha'\u001b[39m, \u001b[33m'Ciudad'\u001b[39m, \u001b[33m'Categoría del problema'\u001b[39m, \u001b[33m'Nivel de Urgencia'\u001b[39m])\n\u001b[32m     13\u001b[39m df[\u001b[33m'Mes'\u001b[39m] = df[\u001b[33m'Fecha'\u001b[39m].dt.to_period(\u001b[33m'M'\u001b[39m)\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Paso 4: Calcular gravedad mensual por ciudad y categoría\u001b[39;00m\n",
            "\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6673\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6674\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6675\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6676\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6677\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6678\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6679\u001b[39m \n\u001b[32m   6680\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
            "\u001b[31mKeyError\u001b[39m: ['Nivel de Urgencia']"
          ]
        }
      ],
      "source": [
        "# Paso 1: Cargar librerías\n",
        "import pandas as pd\n",
        "\n",
        "# Paso 2: Subir y cargar el dataset\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('dataset_procesado_para_prediccion.csv')\n",
        "\n",
        "# Paso 3: Convertir fecha y crear mes\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha del reporte'], format='%Y %m %d', errors='coerce')\n",
        "df = df.dropna(subset=['Fecha', 'Ciudad', 'Categoría del problema', 'Nivel de Urgencia'])\n",
        "df['Mes'] = df['Fecha'].dt.to_period('M')\n",
        "\n",
        "# Paso 4: Calcular gravedad mensual por ciudad y categoría\n",
        "gravedad_mensual = df.groupby(['Ciudad', 'Categoría del problema', 'Mes']).agg(\n",
        "    Gravedad=('Nivel de Urgencia', 'sum'),\n",
        "    Urgencia_Promedio=('Nivel de Urgencia', 'mean'),\n",
        "    Reportes=('Nivel de Urgencia', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Convertir Mes a timestamp para operar\n",
        "gravedad_mensual['Mes_dt'] = gravedad_mensual['Mes'].dt.start_time\n",
        "\n",
        "# Paso 5: Definir \"reciente\" = últimos 3 meses completos\n",
        "todos_los_meses = sorted(gravedad_mensual['Mes_dt'].unique())\n",
        "if len(todos_los_meses) < 4:\n",
        "    print(\"⚠️ Menos de 4 meses de datos. Usando todos los datos disponibles.\")\n",
        "    meses_recientes = todos_los_meses\n",
        "else:\n",
        "    meses_recientes = todos_los_meses[-3:]\n",
        "\n",
        "# Separar datos recientes e históricos\n",
        "reciente = gravedad_mensual[gravedad_mensual['Mes_dt'].isin(meses_recientes)]\n",
        "historico = gravedad_mensual[~gravedad_mensual['Mes_dt'].isin(meses_recientes)]\n",
        "\n",
        "# Paso 6: Agregar estadísticas\n",
        "hist_stats = historico.groupby(['Ciudad', 'Categoría del problema'])['Gravedad'].mean().rename('Gravedad_Hist_Mean').reset_index()\n",
        "rec_stats = reciente.groupby(['Ciudad', 'Categoría del problema'])['Gravedad'].mean().rename('Gravedad_Rec_Mean').reset_index()\n",
        "urg_rec = reciente.groupby(['Ciudad', 'Categoría del problema'])['Urgencia_Promedio'].mean().rename('Urgencia_Rec_Prom').reset_index()\n",
        "\n",
        "# Combinar\n",
        "alertas = hist_stats.merge(rec_stats, on=['Ciudad', 'Categoría del problema'], how='outer').fillna(0)\n",
        "alertas = alertas.merge(urg_rec, on=['Ciudad', 'Categoría del problema'], how='left').fillna(0)\n",
        "\n",
        "# Calcular crecimiento (%)\n",
        "alertas['Crecimiento (%)'] = ((alertas['Gravedad_Rec_Mean'] - alertas['Gravedad_Hist_Mean']) /\n",
        "                              (alertas['Gravedad_Hist_Mean'] + 1e-5)) * 100\n",
        "\n",
        "# Paso 7: Filtrar alertas críticas\n",
        "alertas_criticas = alertas[\n",
        "    (alertas['Crecimiento (%)'] > 25) &           # Aumento >25%\n",
        "    (alertas['Urgencia_Rec_Prom'] >= 3.0) &      # Urgencia alta\n",
        "    (alertas['Gravedad_Rec_Mean'] > 2)            # Al menos algo de actividad reciente\n",
        "].sort_values('Crecimiento (%)', ascending=False)\n",
        "\n",
        "# Paso 8: Mostrar resultados\n",
        "print(\"🚨 ALERTAS DE PROBLEMAS EMERGENTES (últimos 3 meses):\")\n",
        "if not alertas_criticas.empty:\n",
        "    print(alertas_criticas[['Ciudad', 'Categoría del problema', 'Crecimiento (%)', 'Urgencia_Rec_Prom']].to_string(index=False))\n",
        "else:\n",
        "    print(\"ℹ️ No hay alertas críticas. Mostrando top 10 con mayor crecimiento:\")\n",
        "    top10 = alertas.sort_values('Crecimiento (%)', ascending=False).head(10)\n",
        "    print(top10[['Ciudad', 'Categoría del problema', 'Crecimiento (%)', 'Urgencia_Rec_Prom']].to_string(index=False))\n",
        "\n",
        "# Guardar resultados\n",
        "alertas.to_csv('alertas_tendencias_ciudad_categoria.csv', index=False)\n",
        "print(\"\\n✅ Resultados guardados en 'alertas_tendencias_ciudad_categoria.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jD3bOFkN4LK",
        "outputId": "cf5691ef-dce8-4bbd-9f31-353a3a76ea23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset_de_prediccion.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Paso 3: Cargar el dataset con comentarios\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset_de_prediccion.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m df.columns = [\u001b[33m'\u001b[39m\u001b[33mCiudad\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mComentario\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCategoría\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCol4\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNivel de Urgencia\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFecha\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Limpiar y convertir\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dataset_de_prediccion.csv'"
          ]
        }
      ],
      "source": [
        "# Paso 1: Instalar librerías\n",
        "%pip install xgboost pandas scikit-learn xgboost --quiet\n",
        "\n",
        "# Paso 2: Importar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from datetime import timedelta\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Paso 3: Cargar el dataset con comentarios\n",
        "df = pd.read_csv('dataset_de_prediccion.csv', header=None)\n",
        "df.columns = ['Ciudad', 'Comentario', 'Categoría', 'Col4', 'Nivel de Urgencia', 'Fecha']\n",
        "\n",
        "# Limpiar y convertir\n",
        "df['Nivel de Urgencia'] = pd.to_numeric(df['Nivel de Urgencia'], errors='coerce')\n",
        "df = df.dropna(subset=['Nivel de Urgencia'])\n",
        "df['Nivel de Urgencia'] = df['Nivel de Urgencia'].astype(int)\n",
        "\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y %m %d', errors='coerce')\n",
        "df = df.dropna(subset=['Fecha', 'Ciudad', 'Categoría', 'Comentario'])\n",
        "df = df.sort_values('Fecha').reset_index(drop=True)\n",
        "\n",
        "print(f\"✅ Datos cargados: {len(df)} registros desde {df['Fecha'].min()} hasta {df['Fecha'].max()}\")\n",
        "\n",
        "# Paso 4: Crear etiqueta: crisis = al menos un reporte con urgencia ≥3 en los próximos 30 días\n",
        "def crear_etiqueta_grupo(grupo):\n",
        "    grupo = grupo.sort_values('Fecha')\n",
        "    fechas = grupo['Fecha'].values\n",
        "    urgencias = grupo['Nivel de Urgencia'].values\n",
        "    etiquetas = []\n",
        "    for fecha_actual in fechas:\n",
        "        ventana = (fechas > fecha_actual) & (fechas <= fecha_actual + np.timedelta64(30, 'D'))\n",
        "        crisis = np.any(urgencias[ventana] >= 3)\n",
        "        etiquetas.append(int(crisis))\n",
        "    grupo['Crisis_30d'] = etiquetas\n",
        "    return grupo\n",
        "\n",
        "df = df.groupby(['Ciudad', 'Categoría']).apply(crear_etiqueta_grupo).reset_index(drop=True)\n",
        "\n",
        "# Paso 5: Crear features avanzados\n",
        "def crear_features_grupo(grupo):\n",
        "    grupo = grupo.sort_values('Fecha')\n",
        "    features = []\n",
        "    for idx, row in grupo.iterrows():\n",
        "        fecha = row['Fecha']\n",
        "        hist = grupo[(grupo['Fecha'] < fecha) & (grupo['Fecha'] >= fecha - timedelta(days=30))]\n",
        "        if len(hist) == 0:\n",
        "            feat = {\n",
        "                'reportes_7d': 0, 'reportes_15d': 0, 'reportes_30d': 0,\n",
        "                'urgencia_prom_30d': 0, 'dias_ultimo_grave': 30,\n",
        "                'tendencia_15d': 0,\n",
        "                'mes_sin': np.sin(2 * np.pi * fecha.month / 12),\n",
        "                'mes_cos': np.cos(2 * np.pi * fecha.month / 12)\n",
        "            }\n",
        "        else:\n",
        "            r7 = hist[hist['Fecha'] >= fecha - timedelta(days=7)].shape[0]\n",
        "            r15 = hist[hist['Fecha'] >= fecha - timedelta(days=15)].shape[0]\n",
        "            r30 = len(hist)\n",
        "            urg_prom = hist['Nivel de Urgencia'].mean()\n",
        "            graves = hist[hist['Nivel de Urgencia'] >= 3]\n",
        "            dias_ultimo = (fecha - graves['Fecha'].max()).days if len(graves) > 0 else 30\n",
        "\n",
        "            hist_15 = hist[hist['Fecha'] >= fecha - timedelta(days=15)]\n",
        "            tendencia = np.polyfit(np.arange(len(hist_15)), hist_15['Nivel de Urgencia'].values, 1)[0] if len(hist_15) > 2 else 0\n",
        "\n",
        "            feat = {\n",
        "                'reportes_7d': r7, 'reportes_15d': r15, 'reportes_30d': r30,\n",
        "                'urgencia_prom_30d': urg_prom, 'dias_ultimo_grave': dias_ultimo,\n",
        "                'tendencia_15d': tendencia,\n",
        "                'mes_sin': np.sin(2 * np.pi * fecha.month / 12),\n",
        "                'mes_cos': np.cos(2 * np.pi * fecha.month / 12)\n",
        "            }\n",
        "        features.append(feat)\n",
        "    return pd.DataFrame(features, index=grupo.index)\n",
        "\n",
        "# Aplicar features\n",
        "feature_dfs = []\n",
        "for (ciudad, cat), g in df.groupby(['Ciudad', 'Categoría']):\n",
        "    feats = crear_features_grupo(g)\n",
        "    feats['Ciudad'] = ciudad\n",
        "    feats['Categoría'] = cat\n",
        "    feature_dfs.append(feats)\n",
        "\n",
        "X_feat = pd.concat(feature_dfs).sort_index()\n",
        "df_final = pd.concat([df, X_feat], axis=1)\n",
        "\n",
        "# Paso 6: Entrenar modelo\n",
        "feature_cols = ['reportes_7d', 'reportes_15d', 'reportes_30d', 'urgencia_prom_30d',\n",
        "                'dias_ultimo_grave', 'tendencia_15d', 'mes_sin', 'mes_cos']\n",
        "\n",
        "X = df_final[feature_cols]\n",
        "y = df_final['Crisis_30d']\n",
        "X = X[~y.isna()]\n",
        "y = y.dropna()\n",
        "\n",
        "if len(X) < 50:\n",
        "    print(\"⚠️ Pocos datos.\")\n",
        "else:\n",
        "    # Validación temporal\n",
        "    tscv = TimeSeriesSplit(n_splits=3)\n",
        "    scores = []\n",
        "    for tr, te in tscv.split(X):\n",
        "        X_tr, X_te = X.iloc[tr], X.iloc[te]\n",
        "        y_tr, y_te = y.iloc[tr], y.iloc[te]\n",
        "        model = XGBClassifier(n_estimators=100, max_depth=4, random_state=42, eval_metric='logloss')\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict_proba(X_te)[:, 1]\n",
        "        if len(np.unique(y_te)) > 1:\n",
        "            scores.append(roc_auc_score(y_te, y_pred))\n",
        "\n",
        "    if scores:\n",
        "        print(f\"📊 AUC promedio: {np.mean(scores):.2f}\")\n",
        "\n",
        "    # Modelo final\n",
        "    model_final = XGBClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
        "    model_final.fit(X, y)\n",
        "\n",
        "    # Preparar datos limpios\n",
        "    df_clean = df_final.reset_index(drop=True)\n",
        "    df_clean = df_clean.loc[:, ~df_clean.columns.duplicated()]\n",
        "    ultimos = df_clean.groupby(['Ciudad', 'Categoría']).tail(1).copy()\n",
        "\n",
        "    # Predecir\n",
        "    X_ult = ultimos[feature_cols]\n",
        "    ultimos['Prob_Crisis_30d'] = model_final.predict_proba(X_ult)[:, 1]\n",
        "\n",
        "    # Umbral dinámico (percentil 90)\n",
        "    umbral = np.percentile(ultimos['Prob_Crisis_30d'], 90)\n",
        "    alertas = ultimos[ultimos['Prob_Crisis_30d'] >= umbral].copy()\n",
        "\n",
        "    # Recomendaciones por palabras clave\n",
        "    def generar_recomendacion(comentario, categoria):\n",
        "        if pd.isna(comentario):\n",
        "            return \"Requiere revisión por especialistas\"\n",
        "        c = comentario.lower()\n",
        "        if \"basura\" in c or \"recoleccion\" in c or \"recolect\" in c:\n",
        "            return \"Aumentar frecuencia de recolección de basura\"\n",
        "        elif \"agua potable\" in c or \"falta agua\" in c:\n",
        "            return \"Verificar suministro de agua potable\"\n",
        "        elif \"médicos\" in c or \"centro de salud\" in c:\n",
        "            return \"Movilizar brigadas médicas o verificar disponibilidad\"\n",
        "        elif \"oscuras\" in c or \"alumbrado\" in c:\n",
        "            return \"Reparar o instalar alumbrado público\"\n",
        "        elif \"internet\" in c or \"biblioteca\" in c or \"centros culturales\" in c:\n",
        "            return \"Activar programas de acceso digital o bibliotecas móviles\"\n",
        "        elif \"escuelas\" in c or \"educación\" in c:\n",
        "            return \"Revisar infraestructura educativa\"\n",
        "        elif \"policía\" in c or \"presencia policial\" in c:\n",
        "            return \"Aumentar patrullaje en zonas críticas\"\n",
        "        elif \"contaminacion\" in c or \"río\" in c:\n",
        "            return \"Monitorear fuentes de contaminación hídrica\"\n",
        "        else:\n",
        "            return \"Requiere revisión por especialistas\"\n",
        "\n",
        "    alertas['Recomendación'] = alertas.apply(\n",
        "        lambda row: generar_recomendacion(row['Comentario'], row['Categoría']), axis=1\n",
        "    )\n",
        "\n",
        "    # Mostrar y guardar\n",
        "    print(f\"\\n🚨 ALERTAS (probabilidad ≥ {umbral:.2%}):\")\n",
        "    salida = alertas[['Ciudad', 'Categoría', 'Prob_Crisis_30d', 'Comentario', 'Recomendación']]\n",
        "    print(salida.to_string(index=False))\n",
        "\n",
        "    salida.to_csv('alertas_con_recomendaciones_especificas.csv', index=False)\n",
        "    print(\"\\n✅ Resultados guardados en 'alertas_con_recomendaciones_especificas.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X1Oa6jLRg4q",
        "outputId": "ecc80fc1-fa61-4fbb-bda8-683916df6ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📋 Informe completo: Problemáticas y soluciones por ciudad\n",
            "      Ciudad      Categoría                                   Comentario  Nivel de Urgencia                                             Recomendación\n",
            "barranquilla      Educación         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            "barranquilla Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminación hídrica\n",
            "barranquilla          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas médicas o verificar disponibilidad\n",
            "barranquilla      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas críticas\n",
            "      bogota      Educación         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            "      bogota Medio Ambiente   hay problemas con la recoleccion de basura                4.0              Aumentar frecuencia de recolección de basura\n",
            "      bogota          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            "      bogota      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado público\n",
            " bucaramanga      Educación         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            " bucaramanga Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminación hídrica\n",
            " bucaramanga          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            " bucaramanga      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado público\n",
            "        cali      Educación no tenemos centros culturales ni bibliotecas                4.0 Activar programas de acceso digital o bibliotecas móviles\n",
            "        cali Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminación hídrica\n",
            "        cali          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas médicas o verificar disponibilidad\n",
            "        cali      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas críticas\n",
            "   cartagena      Educación no tenemos centros culturales ni bibliotecas                4.0 Activar programas de acceso digital o bibliotecas móviles\n",
            "   cartagena Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminación hídrica\n",
            "   cartagena          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas médicas o verificar disponibilidad\n",
            "   cartagena      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas críticas\n",
            "      cucuta      Educación no tenemos centros culturales ni bibliotecas                4.0 Activar programas de acceso digital o bibliotecas móviles\n",
            "      cucuta Medio Ambiente           las basuras no se recogen a tiempo                4.0              Aumentar frecuencia de recolección de basura\n",
            "      cucuta          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            "      cucuta      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas críticas\n",
            "   manizales      Educación         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            "   manizales Medio Ambiente   hay problemas con la recoleccion de basura                4.0              Aumentar frecuencia de recolección de basura\n",
            "   manizales          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas médicas o verificar disponibilidad\n",
            "   manizales      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas críticas\n",
            "    medellin      Educación necesitamos mas acceso a internet en la zona                4.0 Activar programas de acceso digital o bibliotecas móviles\n",
            "    medellin Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminación hídrica\n",
            "    medellin          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            "    medellin      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas críticas\n",
            "     pereira      Educación necesitamos mas acceso a internet en la zona                4.0 Activar programas de acceso digital o bibliotecas móviles\n",
            "     pereira Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminación hídrica\n",
            "     pereira          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas médicas o verificar disponibilidad\n",
            "     pereira      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado público\n",
            " santa marta      Educación necesitamos mas acceso a internet en la zona                4.0 Activar programas de acceso digital o bibliotecas móviles\n",
            " santa marta Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminación hídrica\n",
            " santa marta          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas médicas o verificar disponibilidad\n",
            " santa marta      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado público\n",
            "\n",
            "✅ Informe guardado en 'informe_ciudades_problematicas_y_soluciones.csv'\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Cargar librerías\n",
        "import pandas as pd\n",
        "\n",
        "# Paso 2: Cargar datos\n",
        "df = pd.read_csv('dataset_final_limpio_ciudades.csv', header=None)\n",
        "df.columns = ['Ciudad', 'Comentario', 'Categoría', 'Col4', 'Nivel de Urgencia', 'Fecha']\n",
        "\n",
        "# Limpiar\n",
        "df['Nivel de Urgencia'] = pd.to_numeric(df['Nivel de Urgencia'], errors='coerce')\n",
        "df = df.dropna(subset=['Ciudad', 'Comentario', 'Categoría', 'Nivel de Urgencia'])\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y %m %d', errors='coerce')\n",
        "\n",
        "# Paso 3: Función de recomendación\n",
        "def generar_recomendacion(comentario, categoria):\n",
        "    c = str(comentario).lower()\n",
        "    if \"basura\" in c or \"recoleccion\" in c or \"recolect\" in c:\n",
        "        return \"Aumentar frecuencia de recolección de basura\"\n",
        "    elif \"agua potable\" in c or \"falta agua\" in c:\n",
        "        return \"Verificar suministro de agua potable\"\n",
        "    elif \"médicos\" in c or \"centro de salud\" in c:\n",
        "        return \"Movilizar brigadas médicas o verificar disponibilidad\"\n",
        "    elif \"oscuras\" in c or \"alumbrado\" in c:\n",
        "        return \"Reparar o instalar alumbrado público\"\n",
        "    elif \"internet\" in c or \"biblioteca\" in c or \"centros culturales\" in c:\n",
        "        return \"Activar programas de acceso digital o bibliotecas móviles\"\n",
        "    elif \"escuelas\" in c or \"educación\" in c:\n",
        "        return \"Revisar infraestructura educativa\"\n",
        "    elif \"policía\" in c or \"presencia policial\" in c:\n",
        "        return \"Aumentar patrullaje en zonas críticas\"\n",
        "    elif \"contaminacion\" in c or \"río\" in c:\n",
        "        return \"Monitorear fuentes de contaminación hídrica\"\n",
        "    else:\n",
        "        return \"Requiere revisión por especialistas\"\n",
        "\n",
        "# Paso 4: Para cada ciudad y categoría, tomar el comentario más grave reciente\n",
        "df['Recomendación'] = df.apply(lambda row: generar_recomendacion(row['Comentario'], row['Categoría']), axis=1)\n",
        "\n",
        "# Ordenar por fecha y urgencia\n",
        "df = df.sort_values(['Ciudad', 'Categoría', 'Nivel de Urgencia', 'Fecha'], ascending=[True, True, False, False])\n",
        "\n",
        "# Tomar el mejor comentario por ciudad+categoría\n",
        "informe = df.groupby(['Ciudad', 'Categoría']).first().reset_index()\n",
        "\n",
        "# Seleccionar columnas útiles\n",
        "resultado = informe[['Ciudad', 'Categoría', 'Comentario', 'Nivel de Urgencia', 'Recomendación']]\n",
        "\n",
        "# Paso 5: Mostrar y guardar\n",
        "print(\"📋 Informe completo: Problemáticas y soluciones por ciudad\")\n",
        "print(resultado.to_string(index=False))\n",
        "\n",
        "resultado.to_csv('informe_ciudades_problematicas_y_soluciones.csv', index=False)\n",
        "print(\"\\n✅ Informe guardado en 'informe_ciudades_problematicas_y_soluciones.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lIk_8cLET9TX",
        "outputId": "3b21d891-6c98-4a5f-f758-e8556af9e635"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_06ce5239-a122-471b-bb67-39f78b609361\", \"alertas.json\", 949)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Convertir alertas a JSON\n",
        "alertas_json = alertas[[\n",
        "    'Ciudad', 'Categoría', 'Prob_Crisis_30d', 'Comentario', 'Recomendación'\n",
        "]].to_dict(orient='records')\n",
        "\n",
        "# Guardar\n",
        "import json\n",
        "with open('alertas.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(alertas_json, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Descargar\n",
        "from google.colab import files\n",
        "files.download('alertas.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3O2tubEnWZKI",
        "outputId": "b51d35a7-765d-45cd-a985-3f6591a3da2d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_44d2ee2b-6457-4a1e-84c9-a2fabcd713cb\", \"problemas_principales_por_ciudad.json\", 2413)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cargar datos\n",
        "df = pd.read_csv('dataset_final_limpio_ciudades.csv', header=None)\n",
        "df.columns = ['Ciudad', 'Comentario', 'Categoría', 'Col4', 'Nivel de Urgencia', 'Fecha']\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y %m %d', errors='coerce')\n",
        "df = df.dropna(subset=['Ciudad', 'Comentario', 'Categoría', 'Nivel de Urgencia'])\n",
        "\n",
        "# Función de recomendación (misma que en landing)\n",
        "def generar_recomendacion(comentario, categoria):\n",
        "    c = str(comentario).lower()\n",
        "    if \"basura\" in c or \"recoleccion\" in c or \"recolect\" in c:\n",
        "        return \"Aumentar frecuencia de recolección de basura\"\n",
        "    elif \"agua potable\" in c or \"falta agua\" in c:\n",
        "        return \"Verificar suministro de agua potable\"\n",
        "    elif \"médicos\" in c or \"centro de salud\" in c:\n",
        "        return \"Movilizar brigadas médicas o verificar disponibilidad\"\n",
        "    elif \"oscuras\" in c or \"alumbrado\" in c:\n",
        "        return \"Reparar o instalar alumbrado público\"\n",
        "    elif \"internet\" in c or \"biblioteca\" in c or \"centros culturales\" in c:\n",
        "        return \"Activar programas de acceso digital o bibliotecas móviles\"\n",
        "    elif \"escuelas\" in c or \"educación\" in c:\n",
        "        return \"Revisar infraestructura educativa\"\n",
        "    elif \"policía\" in c or \"presencia policial\" in c:\n",
        "        return \"Aumentar patrullaje en zonas críticas\"\n",
        "    elif \"contaminacion\" in c or \"río\" in c:\n",
        "        return \"Monitorear fuentes de contaminación hídrica\"\n",
        "    else:\n",
        "        return \"Requiere revisión por especialistas\"\n",
        "\n",
        "df['Recomendación'] = df.apply(lambda row: generar_recomendacion(row['Comentario'], row['Categoría']), axis=1)\n",
        "\n",
        "# Ordenar: mayor urgencia primero, luego más reciente\n",
        "df = df.sort_values(['Ciudad', 'Nivel de Urgencia', 'Fecha'], ascending=[True, False, False])\n",
        "\n",
        "# Tomar el primer registro por ciudad (el más grave y reciente)\n",
        "problemas_principales = df.groupby('Ciudad').first().reset_index()\n",
        "\n",
        "# Seleccionar columnas útiles\n",
        "resultado = problemas_principales[[\n",
        "    'Ciudad', 'Categoría', 'Nivel de Urgencia', 'Comentario', 'Recomendación'\n",
        "]]\n",
        "\n",
        "# Guardar como JSON\n",
        "import json\n",
        "with open('problemas_principales_por_ciudad.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(resultado.to_dict(orient='records'), f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Descargar\n",
        "from google.colab import files\n",
        "files.download('problemas_principales_por_ciudad.json')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
