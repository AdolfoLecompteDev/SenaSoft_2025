{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "1oPnVfHEoCkw",
        "outputId": "05359624-3852-488a-d242-5d741e81f167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset cargado exitosamente.\n",
            "Filas originales: 9236\n",
            "Filas despu√©s de eliminar nulos/vac√≠os en 'Ciudad' o 'Comentario': 9236\n",
            "Columna 'Comentario' eliminada.\n",
            "\n",
            "Dataset despu√©s de la limpieza:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ciudad</th>\n",
              "      <th>Categor√≠a del problema</th>\n",
              "      <th>Categoria numerica</th>\n",
              "      <th>Nivel de urgencia</th>\n",
              "      <th>Fecha del reporte</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Manizales</td>\n",
              "      <td>Seguridad</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-08-11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Santa Marta</td>\n",
              "      <td>Educaci√≥n</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-04-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Medell√≠n</td>\n",
              "      <td>Medio Ambiente</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-06-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bogot√°</td>\n",
              "      <td>Medio Ambiente</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-06-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Manizales</td>\n",
              "      <td>Educaci√≥n</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2024-07-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Ciudad Categor√≠a del problema  Categoria numerica  Nivel de urgencia  \\\n",
              "0    Manizales              Seguridad                   3                  3   \n",
              "1  Santa Marta              Educaci√≥n                   2                  1   \n",
              "2     Medell√≠n         Medio Ambiente                   4                  1   \n",
              "3       Bogot√°         Medio Ambiente                   4                  1   \n",
              "4    Manizales              Educaci√≥n                   2                  4   \n",
              "\n",
              "  Fecha del reporte  \n",
              "0        2023-08-11  \n",
              "1        2023-04-12  \n",
              "2        2023-06-09  \n",
              "3        2023-06-04  \n",
              "4        2024-07-10  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Filas finales: 9236\n",
            "\n",
            "Dataset procesado guardado como dataset_procesado_para_prediccion.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el dataset que contiene las columnas necesarias\n",
        "try:\n",
        "    df = pd.read_csv(\"dataset_final_preparado.csv\")\n",
        "    print(\"Dataset cargado exitosamente.\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: dataset_final_preparado.csv no encontrado. Aseg√∫rate de que el archivo existe.\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Filas originales: {len(df)}\")\n",
        "\n",
        "# Eliminar filas con valores nulos o vac√≠os en 'Ciudad' y 'Comentario'\n",
        "# Keep original df for potential future use before dropping columns\n",
        "df_cleaned = df.dropna(subset=['Ciudad', 'Comentario']).copy()\n",
        "df_cleaned = df_cleaned[df_cleaned['Ciudad'].astype(str).str.strip() != '']\n",
        "df_cleaned = df_cleaned[df_cleaned['Comentario'].astype(str).str.strip() != '']\n",
        "\n",
        "print(f\"Filas despu√©s de eliminar nulos/vac√≠os en 'Ciudad' o 'Comentario': {len(df_cleaned)}\")\n",
        "\n",
        "# Eliminar la columna 'Comentario'\n",
        "if 'Comentario' in df_cleaned.columns:\n",
        "    df_cleaned = df_cleaned.drop(columns=['Comentario']).copy()\n",
        "    print(\"Columna 'Comentario' eliminada.\")\n",
        "\n",
        "# Now, instead of selecting a subset, keep all remaining columns\n",
        "df_procesado = df_cleaned.copy()\n",
        "\n",
        "print(\"\\nDataset despu√©s de la limpieza:\")\n",
        "display(df_procesado.head())\n",
        "\n",
        "print(f\"\\nFilas finales: {len(df_procesado)}\")\n",
        "\n",
        "# Puedes guardar este DataFrame procesado si lo necesitas para pasos posteriores\n",
        "df_procesado.to_csv(\"dataset_procesado_para_prediccion.csv\", index=False)\n",
        "print(\"\\nDataset procesado guardado como dataset_procesado_para_prediccion.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co1k94E79GvN",
        "outputId": "535249c4-a5ae-43ac-9114-16bad0520630"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "['Nivel de Urgencia']",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_7376\\67310600.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m df = pd.read_csv(\u001b[33m'dataset_procesado_para_prediccion.csv'\u001b[39m)\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Paso 3: Convertir fecha y crear mes\u001b[39;00m\n\u001b[32m     11\u001b[39m df[\u001b[33m'Fecha'\u001b[39m] = pd.to_datetime(df[\u001b[33m'Fecha del reporte'\u001b[39m], format=\u001b[33m'%Y %m %d'\u001b[39m, errors=\u001b[33m'coerce'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m df = df.dropna(subset=[\u001b[33m'Fecha'\u001b[39m, \u001b[33m'Ciudad'\u001b[39m, \u001b[33m'Categor√≠a del problema'\u001b[39m, \u001b[33m'Nivel de Urgencia'\u001b[39m])\n\u001b[32m     13\u001b[39m df[\u001b[33m'Mes'\u001b[39m] = df[\u001b[33m'Fecha'\u001b[39m].dt.to_period(\u001b[33m'M'\u001b[39m)\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Paso 4: Calcular gravedad mensual por ciudad y categor√≠a\u001b[39;00m\n",
            "\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6673\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6674\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6675\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6676\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6677\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6678\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6679\u001b[39m \n\u001b[32m   6680\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
            "\u001b[31mKeyError\u001b[39m: ['Nivel de Urgencia']"
          ]
        }
      ],
      "source": [
        "# Paso 1: Cargar librer√≠as\n",
        "import pandas as pd\n",
        "\n",
        "# Paso 2: Subir y cargar el dataset\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv('dataset_procesado_para_prediccion.csv')\n",
        "\n",
        "# Paso 3: Convertir fecha y crear mes\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha del reporte'], format='%Y %m %d', errors='coerce')\n",
        "df = df.dropna(subset=['Fecha', 'Ciudad', 'Categor√≠a del problema', 'Nivel de Urgencia'])\n",
        "df['Mes'] = df['Fecha'].dt.to_period('M')\n",
        "\n",
        "# Paso 4: Calcular gravedad mensual por ciudad y categor√≠a\n",
        "gravedad_mensual = df.groupby(['Ciudad', 'Categor√≠a del problema', 'Mes']).agg(\n",
        "    Gravedad=('Nivel de Urgencia', 'sum'),\n",
        "    Urgencia_Promedio=('Nivel de Urgencia', 'mean'),\n",
        "    Reportes=('Nivel de Urgencia', 'count')\n",
        ").reset_index()\n",
        "\n",
        "# Convertir Mes a timestamp para operar\n",
        "gravedad_mensual['Mes_dt'] = gravedad_mensual['Mes'].dt.start_time\n",
        "\n",
        "# Paso 5: Definir \"reciente\" = √∫ltimos 3 meses completos\n",
        "todos_los_meses = sorted(gravedad_mensual['Mes_dt'].unique())\n",
        "if len(todos_los_meses) < 4:\n",
        "    print(\"‚ö†Ô∏è Menos de 4 meses de datos. Usando todos los datos disponibles.\")\n",
        "    meses_recientes = todos_los_meses\n",
        "else:\n",
        "    meses_recientes = todos_los_meses[-3:]\n",
        "\n",
        "# Separar datos recientes e hist√≥ricos\n",
        "reciente = gravedad_mensual[gravedad_mensual['Mes_dt'].isin(meses_recientes)]\n",
        "historico = gravedad_mensual[~gravedad_mensual['Mes_dt'].isin(meses_recientes)]\n",
        "\n",
        "# Paso 6: Agregar estad√≠sticas\n",
        "hist_stats = historico.groupby(['Ciudad', 'Categor√≠a del problema'])['Gravedad'].mean().rename('Gravedad_Hist_Mean').reset_index()\n",
        "rec_stats = reciente.groupby(['Ciudad', 'Categor√≠a del problema'])['Gravedad'].mean().rename('Gravedad_Rec_Mean').reset_index()\n",
        "urg_rec = reciente.groupby(['Ciudad', 'Categor√≠a del problema'])['Urgencia_Promedio'].mean().rename('Urgencia_Rec_Prom').reset_index()\n",
        "\n",
        "# Combinar\n",
        "alertas = hist_stats.merge(rec_stats, on=['Ciudad', 'Categor√≠a del problema'], how='outer').fillna(0)\n",
        "alertas = alertas.merge(urg_rec, on=['Ciudad', 'Categor√≠a del problema'], how='left').fillna(0)\n",
        "\n",
        "# Calcular crecimiento (%)\n",
        "alertas['Crecimiento (%)'] = ((alertas['Gravedad_Rec_Mean'] - alertas['Gravedad_Hist_Mean']) /\n",
        "                              (alertas['Gravedad_Hist_Mean'] + 1e-5)) * 100\n",
        "\n",
        "# Paso 7: Filtrar alertas cr√≠ticas\n",
        "alertas_criticas = alertas[\n",
        "    (alertas['Crecimiento (%)'] > 25) &           # Aumento >25%\n",
        "    (alertas['Urgencia_Rec_Prom'] >= 3.0) &      # Urgencia alta\n",
        "    (alertas['Gravedad_Rec_Mean'] > 2)            # Al menos algo de actividad reciente\n",
        "].sort_values('Crecimiento (%)', ascending=False)\n",
        "\n",
        "# Paso 8: Mostrar resultados\n",
        "print(\"üö® ALERTAS DE PROBLEMAS EMERGENTES (√∫ltimos 3 meses):\")\n",
        "if not alertas_criticas.empty:\n",
        "    print(alertas_criticas[['Ciudad', 'Categor√≠a del problema', 'Crecimiento (%)', 'Urgencia_Rec_Prom']].to_string(index=False))\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è No hay alertas cr√≠ticas. Mostrando top 10 con mayor crecimiento:\")\n",
        "    top10 = alertas.sort_values('Crecimiento (%)', ascending=False).head(10)\n",
        "    print(top10[['Ciudad', 'Categor√≠a del problema', 'Crecimiento (%)', 'Urgencia_Rec_Prom']].to_string(index=False))\n",
        "\n",
        "# Guardar resultados\n",
        "alertas.to_csv('alertas_tendencias_ciudad_categoria.csv', index=False)\n",
        "print(\"\\n‚úÖ Resultados guardados en 'alertas_tendencias_ciudad_categoria.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jD3bOFkN4LK",
        "outputId": "cf5691ef-dce8-4bbd-9f31-353a3a76ea23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'dataset_de_prediccion.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Paso 3: Cargar el dataset con comentarios\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdataset_de_prediccion.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m df.columns = [\u001b[33m'\u001b[39m\u001b[33mCiudad\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mComentario\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCategor√≠a\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mCol4\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mNivel de Urgencia\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mFecha\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Limpiar y convertir\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\adolf\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dataset_de_prediccion.csv'"
          ]
        }
      ],
      "source": [
        "# Paso 1: Instalar librer√≠as\n",
        "%pip install xgboost pandas scikit-learn xgboost --quiet\n",
        "\n",
        "# Paso 2: Importar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from datetime import timedelta\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Paso 3: Cargar el dataset con comentarios\n",
        "df = pd.read_csv('dataset_de_prediccion.csv', header=None)\n",
        "df.columns = ['Ciudad', 'Comentario', 'Categor√≠a', 'Col4', 'Nivel de Urgencia', 'Fecha']\n",
        "\n",
        "# Limpiar y convertir\n",
        "df['Nivel de Urgencia'] = pd.to_numeric(df['Nivel de Urgencia'], errors='coerce')\n",
        "df = df.dropna(subset=['Nivel de Urgencia'])\n",
        "df['Nivel de Urgencia'] = df['Nivel de Urgencia'].astype(int)\n",
        "\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y %m %d', errors='coerce')\n",
        "df = df.dropna(subset=['Fecha', 'Ciudad', 'Categor√≠a', 'Comentario'])\n",
        "df = df.sort_values('Fecha').reset_index(drop=True)\n",
        "\n",
        "print(f\"‚úÖ Datos cargados: {len(df)} registros desde {df['Fecha'].min()} hasta {df['Fecha'].max()}\")\n",
        "\n",
        "# Paso 4: Crear etiqueta: crisis = al menos un reporte con urgencia ‚â•3 en los pr√≥ximos 30 d√≠as\n",
        "def crear_etiqueta_grupo(grupo):\n",
        "    grupo = grupo.sort_values('Fecha')\n",
        "    fechas = grupo['Fecha'].values\n",
        "    urgencias = grupo['Nivel de Urgencia'].values\n",
        "    etiquetas = []\n",
        "    for fecha_actual in fechas:\n",
        "        ventana = (fechas > fecha_actual) & (fechas <= fecha_actual + np.timedelta64(30, 'D'))\n",
        "        crisis = np.any(urgencias[ventana] >= 3)\n",
        "        etiquetas.append(int(crisis))\n",
        "    grupo['Crisis_30d'] = etiquetas\n",
        "    return grupo\n",
        "\n",
        "df = df.groupby(['Ciudad', 'Categor√≠a']).apply(crear_etiqueta_grupo).reset_index(drop=True)\n",
        "\n",
        "# Paso 5: Crear features avanzados\n",
        "def crear_features_grupo(grupo):\n",
        "    grupo = grupo.sort_values('Fecha')\n",
        "    features = []\n",
        "    for idx, row in grupo.iterrows():\n",
        "        fecha = row['Fecha']\n",
        "        hist = grupo[(grupo['Fecha'] < fecha) & (grupo['Fecha'] >= fecha - timedelta(days=30))]\n",
        "        if len(hist) == 0:\n",
        "            feat = {\n",
        "                'reportes_7d': 0, 'reportes_15d': 0, 'reportes_30d': 0,\n",
        "                'urgencia_prom_30d': 0, 'dias_ultimo_grave': 30,\n",
        "                'tendencia_15d': 0,\n",
        "                'mes_sin': np.sin(2 * np.pi * fecha.month / 12),\n",
        "                'mes_cos': np.cos(2 * np.pi * fecha.month / 12)\n",
        "            }\n",
        "        else:\n",
        "            r7 = hist[hist['Fecha'] >= fecha - timedelta(days=7)].shape[0]\n",
        "            r15 = hist[hist['Fecha'] >= fecha - timedelta(days=15)].shape[0]\n",
        "            r30 = len(hist)\n",
        "            urg_prom = hist['Nivel de Urgencia'].mean()\n",
        "            graves = hist[hist['Nivel de Urgencia'] >= 3]\n",
        "            dias_ultimo = (fecha - graves['Fecha'].max()).days if len(graves) > 0 else 30\n",
        "\n",
        "            hist_15 = hist[hist['Fecha'] >= fecha - timedelta(days=15)]\n",
        "            tendencia = np.polyfit(np.arange(len(hist_15)), hist_15['Nivel de Urgencia'].values, 1)[0] if len(hist_15) > 2 else 0\n",
        "\n",
        "            feat = {\n",
        "                'reportes_7d': r7, 'reportes_15d': r15, 'reportes_30d': r30,\n",
        "                'urgencia_prom_30d': urg_prom, 'dias_ultimo_grave': dias_ultimo,\n",
        "                'tendencia_15d': tendencia,\n",
        "                'mes_sin': np.sin(2 * np.pi * fecha.month / 12),\n",
        "                'mes_cos': np.cos(2 * np.pi * fecha.month / 12)\n",
        "            }\n",
        "        features.append(feat)\n",
        "    return pd.DataFrame(features, index=grupo.index)\n",
        "\n",
        "# Aplicar features\n",
        "feature_dfs = []\n",
        "for (ciudad, cat), g in df.groupby(['Ciudad', 'Categor√≠a']):\n",
        "    feats = crear_features_grupo(g)\n",
        "    feats['Ciudad'] = ciudad\n",
        "    feats['Categor√≠a'] = cat\n",
        "    feature_dfs.append(feats)\n",
        "\n",
        "X_feat = pd.concat(feature_dfs).sort_index()\n",
        "df_final = pd.concat([df, X_feat], axis=1)\n",
        "\n",
        "# Paso 6: Entrenar modelo\n",
        "feature_cols = ['reportes_7d', 'reportes_15d', 'reportes_30d', 'urgencia_prom_30d',\n",
        "                'dias_ultimo_grave', 'tendencia_15d', 'mes_sin', 'mes_cos']\n",
        "\n",
        "X = df_final[feature_cols]\n",
        "y = df_final['Crisis_30d']\n",
        "X = X[~y.isna()]\n",
        "y = y.dropna()\n",
        "\n",
        "if len(X) < 50:\n",
        "    print(\"‚ö†Ô∏è Pocos datos.\")\n",
        "else:\n",
        "    # Validaci√≥n temporal\n",
        "    tscv = TimeSeriesSplit(n_splits=3)\n",
        "    scores = []\n",
        "    for tr, te in tscv.split(X):\n",
        "        X_tr, X_te = X.iloc[tr], X.iloc[te]\n",
        "        y_tr, y_te = y.iloc[tr], y.iloc[te]\n",
        "        model = XGBClassifier(n_estimators=100, max_depth=4, random_state=42, eval_metric='logloss')\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict_proba(X_te)[:, 1]\n",
        "        if len(np.unique(y_te)) > 1:\n",
        "            scores.append(roc_auc_score(y_te, y_pred))\n",
        "\n",
        "    if scores:\n",
        "        print(f\"üìä AUC promedio: {np.mean(scores):.2f}\")\n",
        "\n",
        "    # Modelo final\n",
        "    model_final = XGBClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
        "    model_final.fit(X, y)\n",
        "\n",
        "    # Preparar datos limpios\n",
        "    df_clean = df_final.reset_index(drop=True)\n",
        "    df_clean = df_clean.loc[:, ~df_clean.columns.duplicated()]\n",
        "    ultimos = df_clean.groupby(['Ciudad', 'Categor√≠a']).tail(1).copy()\n",
        "\n",
        "    # Predecir\n",
        "    X_ult = ultimos[feature_cols]\n",
        "    ultimos['Prob_Crisis_30d'] = model_final.predict_proba(X_ult)[:, 1]\n",
        "\n",
        "    # Umbral din√°mico (percentil 90)\n",
        "    umbral = np.percentile(ultimos['Prob_Crisis_30d'], 90)\n",
        "    alertas = ultimos[ultimos['Prob_Crisis_30d'] >= umbral].copy()\n",
        "\n",
        "    # Recomendaciones por palabras clave\n",
        "    def generar_recomendacion(comentario, categoria):\n",
        "        if pd.isna(comentario):\n",
        "            return \"Requiere revisi√≥n por especialistas\"\n",
        "        c = comentario.lower()\n",
        "        if \"basura\" in c or \"recoleccion\" in c or \"recolect\" in c:\n",
        "            return \"Aumentar frecuencia de recolecci√≥n de basura\"\n",
        "        elif \"agua potable\" in c or \"falta agua\" in c:\n",
        "            return \"Verificar suministro de agua potable\"\n",
        "        elif \"m√©dicos\" in c or \"centro de salud\" in c:\n",
        "            return \"Movilizar brigadas m√©dicas o verificar disponibilidad\"\n",
        "        elif \"oscuras\" in c or \"alumbrado\" in c:\n",
        "            return \"Reparar o instalar alumbrado p√∫blico\"\n",
        "        elif \"internet\" in c or \"biblioteca\" in c or \"centros culturales\" in c:\n",
        "            return \"Activar programas de acceso digital o bibliotecas m√≥viles\"\n",
        "        elif \"escuelas\" in c or \"educaci√≥n\" in c:\n",
        "            return \"Revisar infraestructura educativa\"\n",
        "        elif \"polic√≠a\" in c or \"presencia policial\" in c:\n",
        "            return \"Aumentar patrullaje en zonas cr√≠ticas\"\n",
        "        elif \"contaminacion\" in c or \"r√≠o\" in c:\n",
        "            return \"Monitorear fuentes de contaminaci√≥n h√≠drica\"\n",
        "        else:\n",
        "            return \"Requiere revisi√≥n por especialistas\"\n",
        "\n",
        "    alertas['Recomendaci√≥n'] = alertas.apply(\n",
        "        lambda row: generar_recomendacion(row['Comentario'], row['Categor√≠a']), axis=1\n",
        "    )\n",
        "\n",
        "    # Mostrar y guardar\n",
        "    print(f\"\\nüö® ALERTAS (probabilidad ‚â• {umbral:.2%}):\")\n",
        "    salida = alertas[['Ciudad', 'Categor√≠a', 'Prob_Crisis_30d', 'Comentario', 'Recomendaci√≥n']]\n",
        "    print(salida.to_string(index=False))\n",
        "\n",
        "    salida.to_csv('alertas_con_recomendaciones_especificas.csv', index=False)\n",
        "    print(\"\\n‚úÖ Resultados guardados en 'alertas_con_recomendaciones_especificas.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X1Oa6jLRg4q",
        "outputId": "ecc80fc1-fa61-4fbb-bda8-683916df6ea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Informe completo: Problem√°ticas y soluciones por ciudad\n",
            "      Ciudad      Categor√≠a                                   Comentario  Nivel de Urgencia                                             Recomendaci√≥n\n",
            "barranquilla      Educaci√≥n         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            "barranquilla Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminaci√≥n h√≠drica\n",
            "barranquilla          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas m√©dicas o verificar disponibilidad\n",
            "barranquilla      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas cr√≠ticas\n",
            "      bogota      Educaci√≥n         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            "      bogota Medio Ambiente   hay problemas con la recoleccion de basura                4.0              Aumentar frecuencia de recolecci√≥n de basura\n",
            "      bogota          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            "      bogota      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado p√∫blico\n",
            " bucaramanga      Educaci√≥n         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            " bucaramanga Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminaci√≥n h√≠drica\n",
            " bucaramanga          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            " bucaramanga      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado p√∫blico\n",
            "        cali      Educaci√≥n no tenemos centros culturales ni bibliotecas                4.0 Activar programas de acceso digital o bibliotecas m√≥viles\n",
            "        cali Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminaci√≥n h√≠drica\n",
            "        cali          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas m√©dicas o verificar disponibilidad\n",
            "        cali      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas cr√≠ticas\n",
            "   cartagena      Educaci√≥n no tenemos centros culturales ni bibliotecas                4.0 Activar programas de acceso digital o bibliotecas m√≥viles\n",
            "   cartagena Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminaci√≥n h√≠drica\n",
            "   cartagena          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas m√©dicas o verificar disponibilidad\n",
            "   cartagena      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas cr√≠ticas\n",
            "      cucuta      Educaci√≥n no tenemos centros culturales ni bibliotecas                4.0 Activar programas de acceso digital o bibliotecas m√≥viles\n",
            "      cucuta Medio Ambiente           las basuras no se recogen a tiempo                4.0              Aumentar frecuencia de recolecci√≥n de basura\n",
            "      cucuta          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            "      cucuta      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas cr√≠ticas\n",
            "   manizales      Educaci√≥n         no hay suficientes escuelas publicas                4.0                         Revisar infraestructura educativa\n",
            "   manizales Medio Ambiente   hay problemas con la recoleccion de basura                4.0              Aumentar frecuencia de recolecci√≥n de basura\n",
            "   manizales          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas m√©dicas o verificar disponibilidad\n",
            "   manizales      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas cr√≠ticas\n",
            "    medellin      Educaci√≥n necesitamos mas acceso a internet en la zona                4.0 Activar programas de acceso digital o bibliotecas m√≥viles\n",
            "    medellin Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminaci√≥n h√≠drica\n",
            "    medellin          Salud           falta agua potable en varias casas                4.0                      Verificar suministro de agua potable\n",
            "    medellin      Seguridad              queremos mas presencia policial                4.0                     Aumentar patrullaje en zonas cr√≠ticas\n",
            "     pereira      Educaci√≥n necesitamos mas acceso a internet en la zona                4.0 Activar programas de acceso digital o bibliotecas m√≥viles\n",
            "     pereira Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminaci√≥n h√≠drica\n",
            "     pereira          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas m√©dicas o verificar disponibilidad\n",
            "     pereira      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado p√∫blico\n",
            " santa marta      Educaci√≥n necesitamos mas acceso a internet en la zona                4.0 Activar programas de acceso digital o bibliotecas m√≥viles\n",
            " santa marta Medio Ambiente     la contaminacion del rio esta aumentando                4.0               Monitorear fuentes de contaminaci√≥n h√≠drica\n",
            " santa marta          Salud         faltan medicos en el centro de salud                4.0     Movilizar brigadas m√©dicas o verificar disponibilidad\n",
            " santa marta      Seguridad    las calles estan muy oscuras y peligrosas                4.0                      Reparar o instalar alumbrado p√∫blico\n",
            "\n",
            "‚úÖ Informe guardado en 'informe_ciudades_problematicas_y_soluciones.csv'\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Cargar librer√≠as\n",
        "import pandas as pd\n",
        "\n",
        "# Paso 2: Cargar datos\n",
        "df = pd.read_csv('dataset_final_limpio_ciudades.csv', header=None)\n",
        "df.columns = ['Ciudad', 'Comentario', 'Categor√≠a', 'Col4', 'Nivel de Urgencia', 'Fecha']\n",
        "\n",
        "# Limpiar\n",
        "df['Nivel de Urgencia'] = pd.to_numeric(df['Nivel de Urgencia'], errors='coerce')\n",
        "df = df.dropna(subset=['Ciudad', 'Comentario', 'Categor√≠a', 'Nivel de Urgencia'])\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y %m %d', errors='coerce')\n",
        "\n",
        "# Paso 3: Funci√≥n de recomendaci√≥n\n",
        "def generar_recomendacion(comentario, categoria):\n",
        "    c = str(comentario).lower()\n",
        "    if \"basura\" in c or \"recoleccion\" in c or \"recolect\" in c:\n",
        "        return \"Aumentar frecuencia de recolecci√≥n de basura\"\n",
        "    elif \"agua potable\" in c or \"falta agua\" in c:\n",
        "        return \"Verificar suministro de agua potable\"\n",
        "    elif \"m√©dicos\" in c or \"centro de salud\" in c:\n",
        "        return \"Movilizar brigadas m√©dicas o verificar disponibilidad\"\n",
        "    elif \"oscuras\" in c or \"alumbrado\" in c:\n",
        "        return \"Reparar o instalar alumbrado p√∫blico\"\n",
        "    elif \"internet\" in c or \"biblioteca\" in c or \"centros culturales\" in c:\n",
        "        return \"Activar programas de acceso digital o bibliotecas m√≥viles\"\n",
        "    elif \"escuelas\" in c or \"educaci√≥n\" in c:\n",
        "        return \"Revisar infraestructura educativa\"\n",
        "    elif \"polic√≠a\" in c or \"presencia policial\" in c:\n",
        "        return \"Aumentar patrullaje en zonas cr√≠ticas\"\n",
        "    elif \"contaminacion\" in c or \"r√≠o\" in c:\n",
        "        return \"Monitorear fuentes de contaminaci√≥n h√≠drica\"\n",
        "    else:\n",
        "        return \"Requiere revisi√≥n por especialistas\"\n",
        "\n",
        "# Paso 4: Para cada ciudad y categor√≠a, tomar el comentario m√°s grave reciente\n",
        "df['Recomendaci√≥n'] = df.apply(lambda row: generar_recomendacion(row['Comentario'], row['Categor√≠a']), axis=1)\n",
        "\n",
        "# Ordenar por fecha y urgencia\n",
        "df = df.sort_values(['Ciudad', 'Categor√≠a', 'Nivel de Urgencia', 'Fecha'], ascending=[True, True, False, False])\n",
        "\n",
        "# Tomar el mejor comentario por ciudad+categor√≠a\n",
        "informe = df.groupby(['Ciudad', 'Categor√≠a']).first().reset_index()\n",
        "\n",
        "# Seleccionar columnas √∫tiles\n",
        "resultado = informe[['Ciudad', 'Categor√≠a', 'Comentario', 'Nivel de Urgencia', 'Recomendaci√≥n']]\n",
        "\n",
        "# Paso 5: Mostrar y guardar\n",
        "print(\"üìã Informe completo: Problem√°ticas y soluciones por ciudad\")\n",
        "print(resultado.to_string(index=False))\n",
        "\n",
        "resultado.to_csv('informe_ciudades_problematicas_y_soluciones.csv', index=False)\n",
        "print(\"\\n‚úÖ Informe guardado en 'informe_ciudades_problematicas_y_soluciones.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "lIk_8cLET9TX",
        "outputId": "3b21d891-6c98-4a5f-f758-e8556af9e635"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_06ce5239-a122-471b-bb67-39f78b609361\", \"alertas.json\", 949)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Convertir alertas a JSON\n",
        "alertas_json = alertas[[\n",
        "    'Ciudad', 'Categor√≠a', 'Prob_Crisis_30d', 'Comentario', 'Recomendaci√≥n'\n",
        "]].to_dict(orient='records')\n",
        "\n",
        "# Guardar\n",
        "import json\n",
        "with open('alertas.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(alertas_json, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Descargar\n",
        "from google.colab import files\n",
        "files.download('alertas.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3O2tubEnWZKI",
        "outputId": "b51d35a7-765d-45cd-a985-3f6591a3da2d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_44d2ee2b-6457-4a1e-84c9-a2fabcd713cb\", \"problemas_principales_por_ciudad.json\", 2413)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cargar datos\n",
        "df = pd.read_csv('dataset_final_limpio_ciudades.csv', header=None)\n",
        "df.columns = ['Ciudad', 'Comentario', 'Categor√≠a', 'Col4', 'Nivel de Urgencia', 'Fecha']\n",
        "df['Fecha'] = pd.to_datetime(df['Fecha'], format='%Y %m %d', errors='coerce')\n",
        "df = df.dropna(subset=['Ciudad', 'Comentario', 'Categor√≠a', 'Nivel de Urgencia'])\n",
        "\n",
        "# Funci√≥n de recomendaci√≥n (misma que en landing)\n",
        "def generar_recomendacion(comentario, categoria):\n",
        "    c = str(comentario).lower()\n",
        "    if \"basura\" in c or \"recoleccion\" in c or \"recolect\" in c:\n",
        "        return \"Aumentar frecuencia de recolecci√≥n de basura\"\n",
        "    elif \"agua potable\" in c or \"falta agua\" in c:\n",
        "        return \"Verificar suministro de agua potable\"\n",
        "    elif \"m√©dicos\" in c or \"centro de salud\" in c:\n",
        "        return \"Movilizar brigadas m√©dicas o verificar disponibilidad\"\n",
        "    elif \"oscuras\" in c or \"alumbrado\" in c:\n",
        "        return \"Reparar o instalar alumbrado p√∫blico\"\n",
        "    elif \"internet\" in c or \"biblioteca\" in c or \"centros culturales\" in c:\n",
        "        return \"Activar programas de acceso digital o bibliotecas m√≥viles\"\n",
        "    elif \"escuelas\" in c or \"educaci√≥n\" in c:\n",
        "        return \"Revisar infraestructura educativa\"\n",
        "    elif \"polic√≠a\" in c or \"presencia policial\" in c:\n",
        "        return \"Aumentar patrullaje en zonas cr√≠ticas\"\n",
        "    elif \"contaminacion\" in c or \"r√≠o\" in c:\n",
        "        return \"Monitorear fuentes de contaminaci√≥n h√≠drica\"\n",
        "    else:\n",
        "        return \"Requiere revisi√≥n por especialistas\"\n",
        "\n",
        "df['Recomendaci√≥n'] = df.apply(lambda row: generar_recomendacion(row['Comentario'], row['Categor√≠a']), axis=1)\n",
        "\n",
        "# Ordenar: mayor urgencia primero, luego m√°s reciente\n",
        "df = df.sort_values(['Ciudad', 'Nivel de Urgencia', 'Fecha'], ascending=[True, False, False])\n",
        "\n",
        "# Tomar el primer registro por ciudad (el m√°s grave y reciente)\n",
        "problemas_principales = df.groupby('Ciudad').first().reset_index()\n",
        "\n",
        "# Seleccionar columnas √∫tiles\n",
        "resultado = problemas_principales[[\n",
        "    'Ciudad', 'Categor√≠a', 'Nivel de Urgencia', 'Comentario', 'Recomendaci√≥n'\n",
        "]]\n",
        "\n",
        "# Guardar como JSON\n",
        "import json\n",
        "with open('problemas_principales_por_ciudad.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(resultado.to_dict(orient='records'), f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# Descargar\n",
        "from google.colab import files\n",
        "files.download('problemas_principales_por_ciudad.json')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
